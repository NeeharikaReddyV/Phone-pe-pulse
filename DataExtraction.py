# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EPKIETbiIvjGydjefcbJnwBdLhVRYrS-
"""

import requests

base_url = 'https://api.github.com/repos/PhonePe/pulse/contents/data/aggregated/transaction/country/india/state'

# Make a request to retrieve the file structure
response = requests.get(base_url)
if response.status_code == 200:
    data = response.json()

    # Extract the state names from the file structure
    state_names = []
    for item in data:
        if item['type'] == 'dir':
            state_name = item['name']
            state_names.append(state_name)

    # Print the state names
    for state in state_names:
        print(state)
else:
    print("Failed to retrieve the state names.")

import requests
import pandas as pd

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/aggregated/transaction/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

# Make an initial request to retrieve the available states
response = requests.get(base_url)
if response.status_code == 200:
    # Extract the states from the response
    states = response.json()

    years = [2018, 2019, 2020, 2021, 2022]
    file_numbers = range(1, 5)

    dfs = []  # Initialize an empty list to store DataFrames

    # Iterate over the available states
    for state in states:
        for year in years:
            for file_number in file_numbers:
                # Construct the URL with the current state, year, and file number
                url = base_url.format(state=state, year=year, file_number=file_number)

                # Retrieve the JSON data from the URL
                response = requests.get(url)
                if response.status_code == 200:
                    # Extract relevant information from the JSON data
                    data = response.json()
                    transaction_data = data['data']['transactionData']

                    # Process the transaction data as needed
                    for item in transaction_data:
                        name = item['name']
                        payment_instruments = item['paymentInstruments']

                        # Convert the data to a DataFrame if needed
                        dt = pd.json_normalize(payment_instruments)
                        dt['name'] = name
                        dt['state'] = state
                        dt['year'] = year
                        dt['file_number'] = file_number

                        dfs.append(dt)  # Append the DataFrame to the list

    if dfs:
        # Concatenate all DataFrames in the list
        df = pd.concat(dfs, ignore_index=True)

        print(df)  # Print the DataFrame

        # Process the data as needed (e.g., save to CSV)
        csv_filename = f'AggregatedTransaction.csv'
        df.to_csv(csv_filename, index=False)
    else:
        print("No data available.")
else:
    print("Failed to retrieve the states.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/aggregated/transaction/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                transaction_data = data['data']['transactionData']

                # Process the transaction data as needed
                for item in transaction_data:
                    name = item['name']
                    payment_instruments = item['paymentInstruments']

                    # Convert the data to a DataFrame if needed
                    dt = pd.json_normalize(payment_instruments)
                    dt['name'] = name
                    dt['state'] = state
                    dt['year'] = year
                    dt['file_number'] = file_number

                    dfs.append(dt)  # Append the DataFrame to the list

if dfs:
    # Concatenate all DataFrames in the list
    df1 = pd.concat(dfs, ignore_index=True)

    print(df)  # Print the DataFrame

    # Process the data as needed (e.g., save to CSV)
    #csv_filename = f'AggregatedTransaction1.csv'
    #df.to_csv(csv_filename, index=False)
else:
    print("No data available.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/aggregated/user/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                users_by_device = data['data']['usersByDevice']

            # Convert the data to a DataFrame if needed
                dt = pd.json_normalize(users_by_device)
                dt['name'] = name
                dt['state'] = state
                dt['year'] = year
                dt['file_number'] = file_number

                dfs.append(dt)  # Append the DataFrame to the list

                # Process the transaction data as needed
                #for item in transaction_data:
                    #name = item['name']
                    #payment_instruments = item['paymentInstruments']



if dfs:
    # Concatenate all DataFrames in the list
    df2 = pd.concat(dfs, ignore_index=True)

    print(df2)  # Print the DataFrame

    # Process the data as needed (e.g., save to CSV)
    #csv_filename = f'AggregatedTransaction1.csv'
    #df.to_csv(csv_filename, index=False)
else:
    print("No data available.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/map/transaction/hover/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                hover_data_list = data['data']['hoverDataList']

                # Process the transaction data as needed
                for item in hover_data_list:
                    name = item['name']
                    metric = item['metric'][0]
                    count = metric['count']
                    amount = round(metric['amount'], 4)

                    # Create a dictionary with the extracted data
                    result = {'name': name, 'count': count, 'amount': amount}
                    result['state'] = state
                    result['year'] = year
                    result['file_number'] = file_number

                    dfs.append(result)  # Append the dictionary to the list

if dfs:
    # Create DataFrame from the list of dictionaries
    df7 = pd.DataFrame(dfs)

    print(df7)  # Print the DataFrame

    # Process the data as needed (e.g., save to CSV)
    #csv_filename = 'AggregatedTransaction.csv'
    #df.to_csv(csv_filename, index=False)
else:
    print("No data available.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/blob/master/data/map/user/hover/country/india/state/andaman-%26-nicobar-islands/2018/3.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                hover_data = data.get('data', {}).get('hoverData')

                if hover_data:
                    # Process the hover data as needed
                    for district, metrics in hover_data.items():
                        registered_users = metrics.get('registeredUsers', 0)
                        app_opens = metrics.get('appOpens', 0)

                        # Create a dictionary with the extracted data
                        result = {'district': district, 'registeredUsers': registered_users, 'appOpens': app_opens}
                        result['state'] = state
                        result['year'] = year
                        result['file_number'] = file_number

                        dfs.append(result)  # Append the dictionary to the list
                else:
                    print(f"No hover data found for state: {state}, year: {year}, file_number: {file_number}")

if dfs:
    # Create DataFrame from the list of dictionaries
    df4 = pd.DataFrame(dfs)

    print(df4)  # Print the DataFrame

else:
    print("No data available.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/top/transaction/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                districts = data['data']['districts']

                # Process the district data as needed
                for district in districts:
                    name = district['entityName']
                    metric = district['metric']
                    count = metric['count']
                    amount = round(metric['amount'], 4)

                    # Create a dictionary with the extracted data
                    result = {'name': name, 'count': count, 'amount': amount}
                    result['state'] = state
                    result['year'] = year
                    result['file_number'] = file_number

                    dfs.append(result)  # Append the dictionary to the list

if dfs:
    # Create DataFrame from the list of dictionaries
    df5 = pd.DataFrame(dfs)

    print(df5)  # Print the DataFrame

    # Process the data as needed (e.g., save to CSV)
    # csv_filename = 'AggregatedTransaction.csv'
    # df.to_csv(csv_filename, index=False)
else:
    print("No data available.")

import requests
import pandas as pd

state_names = [
    'andaman-%26-nicobar-islands',
    'andhra-pradesh',
    'arunachal-pradesh',
    'assam',
    'bihar',
    'chandigarh',
    'chhattisgarh',
    'dadra-nagar-haveli',
    'daman-diu',
    'delhi',
    'goa',
    'gujarat',
    'haryana',
    'himachal-pradesh',
    'jammu-kashmir',
    'jharkhand',
    'karnataka',
    'kerala',
    'ladakh',
    'lakshadweep',
    'madhya-pradesh',
    'maharashtra',
    'manipur',
    'meghalaya',
    'mizoram',
    'nagaland',
    'odisha',
    'puducherry',
    'punjab',
    'rajasthan',
    'sikkim',
    'tamil-nadu',
    'telangana',
    'tripura',
    'uttar-pradesh',
    'uttarakhand',
    'west-bengal'
]

base_url = 'https://raw.githubusercontent.com/PhonePe/pulse/master/data/aggregated/transaction/country/india/state/andaman-%26-nicobar-islands/2018/1.json'

years = [2018, 2019, 2020, 2021, 2022]
file_numbers = range(1, 5)

dfs = []  # Initialize an empty list to store DataFrames

# Iterate over the available states
for state in state_names:
    for year in years:
        for file_number in file_numbers:
            # Construct the URL with the current state, year, and file number
            url = base_url.format(state=state, year=year, file_number=file_number)

            # Retrieve the JSON data from the URL
            response = requests.get(url)
            if response.status_code == 200:
                # Extract relevant information from the JSON data
                data = response.json()
                transaction_data = data['data']['transactionData']

                # Process the transaction data as needed
                for item in transaction_data:
                    name = item['name']
                    payment_instruments = item['paymentInstruments']

                    # Convert the data to a DataFrame if needed
                    dt = pd.json_normalize(payment_instruments)
                    dt['name'] = name
                    dt['state'] = state
                    dt['year'] = year
                    dt['file_number'] = file_number

                    dfs.append(dt)  # Append the DataFrame to the list

if dfs:
    # Concatenate all DataFrames in the list
    df6 = pd.concat(dfs, ignore_index=True)

    print(df6)  # Print the DataFrame

    # Process the data as needed (e.g., save to CSV)
    #csv_filename = f'AggregatedTransaction1.csv'
    #df.to_csv(csv_filename, index=False)
else:
    print("No data available.")

import pandas as pd

df1.head()

df1.state.unique()

#df1.state.replace(to_replace='andaman-%26-nicobar-islands','Andaman Nicobar Islands'])
#df1['state'] = df1['state'].replace(['andaman-%26-nicobar-islands'], 'Andaman Nicobar Islands')
df1['state'] = df1['state'].replace(['andhra-pradesh', 'arunachal-pradesh', 'assam' , 'bihar', 'chandigarh','chhattisgarh','dadra-nagar-haveli','daman-diu','delhi', 'goa', 'gujarat',
       'haryana', 'himachal-pradesh', 'jammu-kashmir', 'jharkhand',
       'karnataka', 'kerala', 'ladakh', 'lakshadweep', 'madhya-pradesh',
       'maharashtra', 'manipur', 'meghalaya', 'mizoram', 'nagaland',
       'odisha', 'puducherry', 'punjab', 'rajasthan', 'sikkim',
       'tamil-nadu', 'telangana', 'tripura', 'uttar-pradesh',
       'uttarakhand', 'west-bengal'],
                                    ['Andhra pradesh', 'Arunachal pradesh','Assam','Bihar','Chandigarh','Chhattisgarh','Dadra Nagar Haveli','Daman Diu','Delhi', 'Goa', 'Gujarat',
       'Haryana', 'Himachal Pradesh', 'Jammu Kashmir', 'Jharkhand',
       'Karnataka', 'Kerala', 'Ladakh', 'Lakshadweep', 'Madhya Pradesh',
       'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland',
       'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Sikkim',
       'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',
       'Uttarakhand', 'West Bengal'])

df1.isnull().sum()

df1.dtypes

df1['amount'] = df1['amount'].astype('int64')

csv_filename = f'AggregatedTransaction.csv'
df1.to_csv(csv_filename, index=False)

df2.head()

#df1['state'] = df1['state'].replace(['andaman-%26-nicobar-islands'], 'Andaman Nicobar Islands')
df2['state'] = df2['state'].replace(['andaman-%26-nicobar-islands','andhra-pradesh', 'arunachal-pradesh', 'assam' , 'bihar', 'chandigarh','chhattisgarh','dadra-nagar-haveli','daman-diu','delhi', 'goa', 'gujarat',
       'haryana', 'himachal-pradesh', 'jammu-kashmir', 'jharkhand',
       'karnataka', 'kerala', 'ladakh', 'lakshadweep', 'madhya-pradesh',
       'maharashtra', 'manipur', 'meghalaya', 'mizoram', 'nagaland',
       'odisha', 'puducherry', 'punjab', 'rajasthan', 'sikkim',
       'tamil-nadu', 'telangana', 'tripura', 'uttar-pradesh',
       'uttarakhand', 'west-bengal'],
                                    ['Andaman Nicobar Islands','Andhra pradesh', 'Arunachal pradesh','Assam','Bihar','Chandigarh','Chhattisgarh','Dadra Nagar Haveli','Daman Diu','Delhi', 'Goa', 'Gujarat',
       'Haryana', 'Himachal Pradesh', 'Jammu Kashmir', 'Jharkhand',
       'Karnataka', 'Kerala', 'Ladakh', 'Lakshadweep', 'Madhya Pradesh',
       'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland',
       'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Sikkim',
       'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',
       'Uttarakhand', 'West Bengal'])

df2.drop('name', axis=1, inplace=True)

df2.isnull().sum()

df2.dtypes

csv_filename = f'AggregatedUser.csv'
df2.to_csv(csv_filename, index=False)

df7.head()

df7['state'] = df7['state'].replace(['andaman-%26-nicobar-islands','andhra-pradesh', 'arunachal-pradesh', 'assam' , 'bihar', 'chandigarh','chhattisgarh','dadra-nagar-haveli','daman-diu','delhi', 'goa', 'gujarat',
       'haryana', 'himachal-pradesh', 'jammu-kashmir', 'jharkhand',
       'karnataka', 'kerala', 'ladakh', 'lakshadweep', 'madhya-pradesh',
       'maharashtra', 'manipur', 'meghalaya', 'mizoram', 'nagaland',
       'odisha', 'puducherry', 'punjab', 'rajasthan', 'sikkim',
       'tamil-nadu', 'telangana', 'tripura', 'uttar-pradesh',
       'uttarakhand', 'west-bengal'],
                                    ['Andaman Nicobar Islands','Andhra pradesh', 'Arunachal pradesh','Assam','Bihar','Chandigarh','Chhattisgarh','Dadra Nagar Haveli','Daman Diu','Delhi', 'Goa', 'Gujarat',
       'Haryana', 'Himachal Pradesh', 'Jammu Kashmir', 'Jharkhand',
       'Karnataka', 'Kerala', 'Ladakh', 'Lakshadweep', 'Madhya Pradesh',
       'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland',
       'Odisha', 'Puducherry', 'Punjab', 'Rajasthan', 'Sikkim',
       'Tamil Nadu', 'Telangana', 'Tripura', 'Uttar Pradesh',
       'Uttarakhand', 'West Bengal'])

df7.isnull().sum()

df7.dtypes

csv_filename = f'MapTransaction.csv'
df7.to_csv(csv_filename, index=False)

"""**Repeat the same process as above to clean other csv files as well"""